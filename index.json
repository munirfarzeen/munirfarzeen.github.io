
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":" I am a postdoctoral researcher at the Mobile Robotics Lab, Aalto University under the mentorship of Professor Tomasz Kuncer . Farzeen Munir received a BS degree in Electrical Engineering from Pakistan Institute of Engineering and Applied Sciences, Pakistan in 2013, and an MS degree in System Engineering from Pakistan Institute of Engineering and Applied Sciences, Pakistan in 2015. She received her PhD from Gwangju Institute of Science and Technology, Korea in 2022.\nIn her PhD, she worked on the system, design, and experimental validation of autonomous vehicle in an unconstrained environment. Currently, she is a postdoctoral researcher, she joined Korea Culture Technology Institute, Gwangju Institute of Science and Technology, South Korea, led by Professor Moongu Jeon, where she worked on developing end-to-end solutions using deep learning for indoor robotics. Her research interest includes deep learning, autonomous driving, visual perception, and representation learning.\n","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640995200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a postdoctoral researcher at the Mobile Robotics Lab, Aalto University under the mentorship of Professor Tomasz Kuncer . Farzeen Munir received a BS degree in Electrical Engineering from Pakistan Institute of Engineering and Applied Sciences, Pakistan in 2013, and an MS degree in System Engineering from Pakistan Institute of Engineering and Applied Sciences, Pakistan in 2015.","tags":null,"title":"Farzeen Munir, PhD","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://munirfarzeen.github.io./talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"The recent development in the field of mobile robotics has made them available for commercial and research purposes. The primary challenges that are encountered by deploying the mobile robot in a dynamic environment is mapping and navigation. Simultaneous localization and mapping (SLAM) provide a good understanding of the environment for navigation and path planning. In this work, we explore the problem of mapping and navigation by incorporating the semantics of the environment. For the experimental setup, a robot (BeetleBot) is designed having equipped with Kobuki mobile base, Realsense RGB-D camera, range sensors and NVidia Jetson Xavier as computation computer. The autonomous semantic mapping and navigation are performed using RTAB-MAP with the inclusion of A* algorithm for exploring and updating the unknown environment and deep learning-based object detection algorithm. A Proportional-Integral-Derivative (PID) is implemented as a controller for the BeetleBOT. We have used the Robot Operating System (ROS) as a software development platform for the BeetleBOT. The experimental evaluation shows the mapping and localization efficacy using the BeetleBOT as our mobile robot.\nOverall architecture of BeetleBot using ROS framework. The demonstration video of the project.\n","date":1645920000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645920000,"objectID":"d632904d292147fa79e5957e8ad0c474","permalink":"https://munirfarzeen.github.io./project/beetlebot/","publishdate":"2022-02-27T00:00:00Z","relpermalink":"/project/beetlebot/","section":"project","summary":"The recent development in the field of mobile robotics has made them available for commercial and research purposes. The primary challenges that are encountered by deploying the mobile robot in a dynamic environment is mapping and navigation.","tags":["Deep Learning","Indoor Robotics","ROS","Obsctale Avoidance"],"title":"BeetleBot","type":"project"},{"authors":["Amnah Nasim","David C Nchekwube","Farzeen Munir, PhD","Yoon Sang Kim"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"f6743e52eb8496a59399a1ccbb665eaf","permalink":"https://munirfarzeen.github.io./publication/nasim-2022-evolutionary/","publishdate":"2022-09-26T08:48:34.406915Z","relpermalink":"/publication/nasim-2022-evolutionary/","section":"publication","summary":"","tags":null,"title":"An Evolutionary-Neural Mechanism for Arrhythmia Classification with Optimum Features using Single-Lead Electrocardiogram","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Unse Fatima","Moongu Jeon"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"f0411cafd5429ffa27ab2b813d550a9c","permalink":"https://munirfarzeen.github.io./publication/munir-2022-artseg/","publishdate":"2022-09-26T08:45:08.120907Z","relpermalink":"/publication/munir-2022-artseg/","section":"publication","summary":"","tags":null,"title":"ARTSeg: Employing Attention for Thermal Images Semantic Segmentation","type":"publication"},{"authors":["Farzeen Munir, PhD"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"3b7b61712d0704f6a0a6e7411a679543","permalink":"https://munirfarzeen.github.io./publication/munir-2022-dynamic/","publishdate":"2022-09-27T03:40:26.905003Z","relpermalink":"/publication/munir-2022-dynamic/","section":"publication","summary":"","tags":null,"title":"Dynamic visual perception for Autonomous vehicles","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Muhammd Aasim Rafique","Ahmad Muqeem Sheri","Moongu Jeon","Witold Pedrycz"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"97024e2f1d85417d12ab8e4ac46f6eec","permalink":"https://munirfarzeen.github.io./publication/munir-2022-exploring/","publishdate":"2022-09-26T08:11:18.846451Z","relpermalink":"/publication/munir-2022-exploring/","section":"publication","summary":"This work proposes a domain adaptation framework that employs a style transfer technique for transfer learning from visible spectrum images to thermal images. The framework uses a generative adversarial network (GAN) to transfer the low- level features from the visible spectrum domain to the thermal domain through style consistency.","tags":[],"title":"Exploring thermal images for object detection in underexposure regions for autonomous driving","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Byung-Geun Lee","Moongu Jeon"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"c7646294312d0fe6ee5e4715c1384017","permalink":"https://munirfarzeen.github.io./publication/munir-2022-multi/","publishdate":"2022-09-26T08:45:08.121073Z","relpermalink":"/publication/munir-2022-multi/","section":"publication","summary":"","tags":null,"title":"Multi-Modal Fusion for Sensorimotor Coordination in Steering Angle Prediction","type":"publication"},{"authors":null,"categories":null,"content":"In this study, we have developed an autonomous vehicle using limited sensor suite as compared to autonomous vehicles discussed previously. Figure illustrates our test-bed called Car.Mlv.ai. The efficacy of our autonomous vehicle is experimentally verified by deploying it as an automated taxi service in the constrained environment. The proposed autonomous vehicle is composed of localization, perception, planning and control modules. The design of a distributed system and incorporation of robust algorithms enable the autonomous vehicle to perform efficiently. The fusion of sensor data for localization in map generation and navigation and also in perception module enable reliable object detection, recognition and classification in a dynamic environment. In the planning module, the optimal path is devised by considering the lane, obstacle information, and upon which velocity and behaviour planning are executed. Finally, based on the planning results, the control module performs the lateral and longitudinal control of the autonomous vehicle.\nOverall architecture of our autonomous vehicle system. It includes sensors, perception, planning and control modules The architecture of the autonomous vehicle is composed of four major layers, as illustrated in Figure above, that are sensor layer, perception layer, planning layer and control layer. The sensor layer constitutes of exteroceptive and proprioceptive sensor modalities which provide the data to the different layer’s modules. In the perception layer, the two main elements that contribute toward the environment understanding are detection and localization. The understanding of the environment in the perception layer provides the necessary information to the planning layer. The planning layer devises the motion, mission and trajectory planning of the autonomous vehicle based on the observation accumulated in the perception layer. The decision from the planning layer is fed to the control layer for the execution of the control command to vehicle actuators through the lateral and longitudinal controller. The following subsections describe the modules used in perception, planning and control layers for the autonomous vehicle.\nThe demonstration video of the project.\nDemo of Avoiding the dog. Demo of Obstacle Stopping at the Entrance or Exit Gate Barrier. Demo of Obstacle Stopping upon detection pedestrain. Driving in the campus. Demo of Obstacle Detection using RGB and Thermal Camera and Projection in the Lidar Frame. News coverage of our project sponsored by GIST. ","date":1619481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619481600,"objectID":"d483befe29824bc50a363c5f23cc0f47","permalink":"https://munirfarzeen.github.io./project/car.mlv.ai/","publishdate":"2021-04-27T00:00:00Z","relpermalink":"/project/car.mlv.ai/","section":"project","summary":"In this study, we have developed an autonomous vehicle using limited sensor suite as compared to autonomous vehicles discussed previously. Figure illustrates our test-bed called Car.Mlv.ai. The efficacy of our autonomous vehicle is experimentally verified by deploying it as an automated taxi service in the constrained environment.","tags":["Deep Learning","Autonomous Vehicle","Sensor Fusion","Obsctale Avoidance"],"title":"Car.MLV.ai~Autonomous Vehicle","type":"project"},{"authors":["Shoaib Azam","Farzeen Munir, PhD","Moongu Jeon"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"b0f24d4d446e26446da3a95d045d85d2","permalink":"https://munirfarzeen.github.io./publication/azam-2021-channel/","publishdate":"2022-09-26T08:45:08.118393Z","relpermalink":"/publication/azam-2021-channel/","section":"publication","summary":"","tags":null,"title":"Channel boosting feature ensemble for radar-based object detection","type":"publication"},{"authors":["Shoaib Azam","Farzeen Munir, PhD","Unse Fatima","Moongu Jeon"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"642744a2de9e7d70e8f9369709b7606a","permalink":"https://munirfarzeen.github.io./publication/azam-2021-emgnet/","publishdate":"2022-09-26T08:45:08.120734Z","relpermalink":"/publication/azam-2021-emgnet/","section":"publication","summary":"","tags":null,"title":"EMGNet: Driver’s Intent Prediction using Neurosignals","type":"publication"},{"authors":["Yeongmin Ko","Younkwan Lee","Shoaib Azam","Farzeen Munir, PhD","Moongu Jeon","Witold Pedrycz"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6ce7f8c9b92e2d4178557c60591a106d","permalink":"https://munirfarzeen.github.io./publication/ko-2021-key/","publishdate":"2022-09-26T08:45:08.118646Z","relpermalink":"/publication/ko-2021-key/","section":"publication","summary":"","tags":null,"title":"Key points estimation and point instance segmentation approach for lane detection","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Moongu Jeon","Byung-Geun Lee","Witold Pedrycz"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"5e14da144c62f7d12427195e7a235153","permalink":"https://munirfarzeen.github.io./publication/munir-2021-ldnet/","publishdate":"2022-09-26T08:45:08.120563Z","relpermalink":"/publication/munir-2021-ldnet/","section":"publication","summary":"This paper explores the novel application of lane marking detection using an event camera by designing a convolutional encoder followed by the attention-guided decoder. The spatial resolution of the encoded features is retained by a dense atrous spatial pyramid pooling (ASPP) block. The additive attention mechanism in the decoder improves performance for high dimensional input encoded features that promote lane localization and relieve postprocessing computation.","tags":[],"title":"LDNet: end-to-end lane marking detection approach using a dynamic vision sensor","type":"publication"},{"authors":["Zafran Khan","Ishfaq Hussain","Farzeen Munir, PhD","Unse Fatima","Shoaib Azam","Moongu Jeon"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"a45bf1d29a3f0c2a71c302e6523d7065","permalink":"https://munirfarzeen.github.io./publication/khan-2021-modified/","publishdate":"2022-09-26T08:45:08.121241Z","relpermalink":"/publication/khan-2021-modified/","section":"publication","summary":"","tags":null,"title":"Modified RC Car for uni-modal Autonomous Parking","type":"publication"},{"authors":["Shoaib Azam","Farzeen Munir, PhD","Muhammad Aasim Rafique","Ahmad Muqeem Sheri","Muhammad Ishfaq Hussain","Moongu Jeon"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"07bb0f39d62ceea566e8434d718d5d3f","permalink":"https://munirfarzeen.github.io./publication/azam-2021-n/","publishdate":"2022-09-26T08:45:08.117587Z","relpermalink":"/publication/azam-2021-n/","section":"publication","summary":"","tags":null,"title":"N 2 C: neural network controller design using behavioral cloning","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Moongu Jeon"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"c5579946738edd00c0c66eb3b557f0b4","permalink":"https://munirfarzeen.github.io./publication/munir-2021-sstn/","publishdate":"2022-09-26T08:45:08.118863Z","relpermalink":"/publication/munir-2021-sstn/","section":"publication","summary":"","tags":null,"title":"SSTN: Self-supervised domain adaptation thermal object detection for autonomous driving","type":"publication"},{"authors":["Farzeen Munir, PhD"],"categories":["Demo"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It’s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy’s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you’ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2022-present Farzeen Munir.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://munirfarzeen.github.io./post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":null,"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Shoaib Azam","Farzeen Munir, PhD","Moongu Jeon"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"5be00508397abb674c75501a21393c6d","permalink":"https://munirfarzeen.github.io./publication/azam-2020-dynamic/","publishdate":"2022-09-26T08:45:08.117107Z","relpermalink":"/publication/azam-2020-dynamic/","section":"publication","summary":"","tags":null,"title":"Dynamic Control System Design for Autonomous Car.","type":"publication"},{"authors":["Muhamamd Ishfaq Hussain","Shoaib Azam","Farzeen Munir, PhD","Zafran Khan","Moongu Jeon"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"7d726d6c1bc0e232e5d768bf55fd10b4","permalink":"https://munirfarzeen.github.io./publication/hussain-2020-multiple/","publishdate":"2022-09-26T08:45:08.120386Z","relpermalink":"/publication/hussain-2020-multiple/","section":"publication","summary":"","tags":null,"title":"Multiple objects tracking using radar for autonomous driving","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Seongmin Hwang","Jihoon Jeong","Moongu Jeon"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"aded44a71f6ac67916b4077dac2e3901","permalink":"https://munirfarzeen.github.io./publication/munir-2020-semantic/","publishdate":"2022-09-26T08:45:08.119941Z","relpermalink":"/publication/munir-2020-semantic/","section":"publication","summary":"","tags":null,"title":"Semantic Mapping and Autonomous Navigation using TurtleBot","type":"publication"},{"authors":["Shoaib Azam","Farzeen Munir, PhD","Ahmad Muqeem Sheri","Joonmo Kim","Moongu Jeon"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"3accb1216069ff4783e62ecbffa528a8","permalink":"https://munirfarzeen.github.io./publication/azam-2020-system/","publishdate":"2022-09-26T08:45:08.116916Z","relpermalink":"/publication/azam-2020-system/","section":"publication","summary":"","tags":null,"title":"System, design and experimental validation of autonomous vehicle in an unconstrained environment","type":"publication"},{"authors":["Vinh Quang Dinh","Farzeen Munir, PhD","Shoaib Azam","Kin-Choong Yow","Moongu Jeon"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"01bfac1961cadcc901992c7e12b37ca3","permalink":"https://munirfarzeen.github.io./publication/dinh-2020-transfer/","publishdate":"2022-09-26T08:45:08.119063Z","relpermalink":"/publication/dinh-2020-transfer/","section":"publication","summary":"","tags":null,"title":"Transfer learning for vehicle detection using two cameras with different focal lengths","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Moongu Jeon"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"f1d7a7252e1785b50363b3cdd2afa23a","permalink":"https://munirfarzeen.github.io./publication/munir-2020-visuomotor/","publishdate":"2022-09-26T08:45:08.116001Z","relpermalink":"/publication/munir-2020-visuomotor/","section":"publication","summary":"","tags":null,"title":"Visuomotor Steering angle Prediction in Dynamic Perception Environment for Autonomous Vehicle","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://munirfarzeen.github.io./slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Linh Van Ma","Shoaib Azam","Farzeen Munir, PhD","Moongu Jeon","Jinho Choi"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"1509247a9e74eff3b2be68d1e96e7866","permalink":"https://munirfarzeen.github.io./publication/van-2019-automated/","publishdate":"2022-09-26T08:45:08.119509Z","relpermalink":"/publication/van-2019-automated/","section":"publication","summary":"","tags":null,"title":"Automated Taxi Booking Operations for Autonomous Vehicles","type":"publication"},{"authors":["Shoaib Azam","Farzeen Munir, PhD","Ahmad Muqeem Sheri","YeongMin Ko","Ishfaq Hussain","Moongu Jeon"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"734155c23efdfd3705d9306a980badda","permalink":"https://munirfarzeen.github.io./publication/azam-2019-data/","publishdate":"2022-09-26T08:45:08.119267Z","relpermalink":"/publication/azam-2019-data/","section":"publication","summary":"","tags":null,"title":"Data fusion of lidar and thermal camera for autonomous driving","type":"publication"},{"authors":["Vinh Quang Dinh","Farzeen Munir, PhD","Ahmad Muqeem Sheri","Moongu Jeon"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"ae8303cf073d5c44929b15b5d2e80eb8","permalink":"https://munirfarzeen.github.io./publication/dinh-2019-disparity/","publishdate":"2022-09-26T08:45:08.118024Z","relpermalink":"/publication/dinh-2019-disparity/","section":"publication","summary":"","tags":null,"title":"Disparity estimation using stereo images with different focal lengths","type":"publication"},{"authors":["Farzeen Munir, PhD","Sadaf Gul","Amina Asif"," others"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"93f4b7eafc86a050c0cd8a8a9e9d9969","permalink":"https://munirfarzeen.github.io./publication/munir-2019-milamp/","publishdate":"2022-09-26T08:45:08.11618Z","relpermalink":"/publication/munir-2019-milamp/","section":"publication","summary":"","tags":null,"title":"MILAMP: multiple instance prediction of amyloid proteins","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Ko Yeongmin","Jihyo Jeon","Moongu Jeon"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"59d1357015f5a01fcf97149d2fb72a0b","permalink":"https://munirfarzeen.github.io./publication/munir-2019-motion/","publishdate":"2022-09-26T08:45:08.115717Z","relpermalink":"/publication/munir-2019-motion/","section":"publication","summary":"","tags":null,"title":"Motion Prediction and Obstacle Avoidance for Self-driving Car","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Ahmad Muqeem Sheri","YeongMin Ko","Moongu Jeon"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"8888897934bb7024f76c2585e9338e84","permalink":"https://munirfarzeen.github.io./publication/munir-2019-localization/","publishdate":"2022-09-26T08:45:08.119695Z","relpermalink":"/publication/munir-2019-localization/","section":"publication","summary":"","tags":null,"title":"Where Am I: Localization and 3D Maps for Autonomous Vehicles.","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Muhammad Ishfaq Hussain","Ahmed Muqeem Sheri","Moongu Jeon"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"d18a132f02bd50fd9e2b84507c1cbdd8","permalink":"https://munirfarzeen.github.io./publication/munir-2018-autonomous/","publishdate":"2022-09-26T08:45:08.11781Z","relpermalink":"/publication/munir-2018-autonomous/","section":"publication","summary":"","tags":null,"title":"Autonomous vehicle: The architecture aspect of self driving car","type":"publication"},{"authors":["Shoaib Azam","Farzeen Munir, PhD","Aasim Rafique","YeongMin Ko","Ahmad Muqeem Sheri","Moongu Jeon"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"0e5bdb0d62c400d58c1221cb30274daf","permalink":"https://munirfarzeen.github.io./publication/azam-2018-object/","publishdate":"2022-09-26T08:45:08.116359Z","relpermalink":"/publication/azam-2018-object/","section":"publication","summary":"","tags":null,"title":"Object modeling from 3d point cloud data for self-driving vehicles","type":"publication"},{"authors":["Farzeen Munir, PhD","Fayyaz ul Amir Asfar Minhas","Abdul Jalil","Moongu Jeon"],"categories":null,"content":"","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"879f7b7c93a0a94e65f7a01407588dc5","permalink":"https://munirfarzeen.github.io./publication/munir-real-2017/","publishdate":"2022-09-26T08:45:08.117314Z","relpermalink":"/publication/munir-real-2017/","section":"publication","summary":"Real time eye tracking has numerous applications in human computer interaction such as a mouse cursor control in a computer system. It is useful for persons with muscular or motion impairments. However, tracking the movement of the eye is complicated by occlusion due to blinking, head movement, screen glare, rapid eye movements, etc. In this work, we present the algorithmic and construction details of a real time eye tracking system. Our proposed system is an extension of Spatio-Temporal context learning through Kalman Filtering. Spatio-Temporal Context Learning offers state of the art accuracy in general object tracking but its performance suffers due to object occlusion. Addition of the Kalman filter allows the proposed method to model the dynamics of the motion of the eye and provide robust eye tracking in cases of occlusion. We demonstrate the effectiveness of this tracking technique by controlling the computer cursor in real time by eye movements.","tags":null,"title":"Real time eye tracking using Kalman extended spatio-temporal context learning","type":"publication"},{"authors":["Farzeen Munir, PhD","Shoaib Azam","Aasim Rafique","Moongu Jeon"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"7280e1a7682f8fa4fc582064f399dde7","permalink":"https://munirfarzeen.github.io./publication/munir-2017-automated/","publishdate":"2022-09-26T08:45:08.116728Z","relpermalink":"/publication/munir-2017-automated/","section":"publication","summary":"","tags":null,"title":"Automated Labelling of 3D Point Cloud Data","type":"publication"},{"authors":["Amina Asif","Wajid Arshad Abbasi","Farzeen Munir, PhD","Asa Ben-Hur"," others"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"fe758a1cd003d3ce613eb5a55071da02","permalink":"https://munirfarzeen.github.io./publication/asif-2017-pylemmings/","publishdate":"2022-09-26T08:45:08.120167Z","relpermalink":"/publication/asif-2017-pylemmings/","section":"publication","summary":"","tags":null,"title":"pyLEMMINGS: Large Margin Multiple Instance Classification and Ranking for Bioinformatics Applications","type":"publication"},{"authors":["Farzeen Munir, PhD"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"74c7cc735d597c372fdf968fcb9cfad5","permalink":"https://munirfarzeen.github.io./publication/munir-2015-spatio/","publishdate":"2022-09-26T08:45:08.116542Z","relpermalink":"/publication/munir-2015-spatio/","section":"publication","summary":"","tags":null,"title":"Spatio-Temporal Visual Object Tracking","type":"publication"},{"authors":["Farzeen Munir, PhD"],"categories":null,"content":"","date":1373673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1373673600,"objectID":"ef618bd86e66e49828e5bf438e7f83bd","permalink":"https://munirfarzeen.github.io./publication/munir-2013-implementation/","publishdate":"2013-09-27T03:40:26.905003Z","relpermalink":"/publication/munir-2013-implementation/","section":"publication","summary":"","tags":null,"title":"Implementation of a Motor Controller for Humanoid Arm","type":"publication"}]